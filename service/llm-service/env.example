# =============================================================================
# LLM Service 환경변수 설정 (FastAPI + RAG + OpenAI & KoAlpaca)
# =============================================================================
# 이 파일을 .env로 복사하고 실제 값으로 수정하세요
# cp env.example .env

# =============================================================================
# 🚀 배포 환경 설정
# =============================================================================
# 배포 환경: development, production, docker, railway
DEPLOYMENT_ENV=development

# =============================================================================
# 🌐 서비스 설정
# =============================================================================
# 서비스 호스트 및 포트
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8002
SERVICE_NAME=llm-service

# =============================================================================
# 📁 FAISS Volume 설정 (vectordb 구조)
# =============================================================================
# FAISS 파일 경로 (모든 환경에서 동일: /app/vectordb)
FAISS_VOLUME_PATH=/app/vectordb
# FAISS 인덱스 폴더명
FAISS_INDEX_NAME=sr_corpus
FAISS_STORE_NAME=sr_corpus

# =============================================================================
# 🔤 임베딩 모델 설정 (이미 임베딩된 FAISS 사용)
# =============================================================================
# 기존 FAISS 인덱스의 차원 (차원 일치 검증용)
EMBED_DIM=768
# OpenAI API 키 (텍스트 생성용만 - 초안/윤문 생성)
OPENAI_API_KEY=your-openai-api-key-here

# =============================================================================
# 🤖 생성 모델 설정
# =============================================================================
# OpenAI Chat Completions API
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.3

# 외부 GPU(vLLM/TGI)에서 KoAlpaca LoRA 병합 모델을 OpenAI 호환으로 제공
GENAI_URL=https://<gpu-host>/v1/chat/completions
GENAI_KEY=<optional>
it
# Hugging Face Inference Endpoint (필수)
HF_ENDPOINT_URL=...
HF_MODEL=jeongtaeyeong/tcfd-polyglot-3.8b-merged
HF_TIMEOUT=30

# Hugging Face Hub 직접 모델 로딩용 토큰 (필수)
# 이 토큰은 Hugging Face Hub에서 모델을 다운로드할 때 사용됩니다
HF_TOKEN=hf_...

# Hugging Face 로컬 모델 설정 (Railway에서 직접 모델 로딩용)
# 이 값이 설정되면 API 호출 대신 로컬 모델을 직접 로드합니다
# 예: HF_LOCAL_MODEL_PATH=/app/models/tcfd-polyglot-3.8b-merged
HF_LOCAL_MODEL_PATH=

# =============================================================================
# 🔒 보안 설정
# =============================================================================
# 관리자 보호 토큰(업로드/리빌드 엔드포인트)
ADMIN_TOKEN=supersecret

# =============================================================================
# 📊 모니터링 설정
# =============================================================================
# 로깅 레벨
LOG_LEVEL=INFO
# 헬스 체크 경로
HEALTH_CHECK_PATH=/health
# 메트릭 수집 여부
ENABLE_METRICS=true
# 로그 수집 여부
ENABLE_LOGGING=true

# =============================================================================
# 🔧 개발 환경 설정
# =============================================================================
# Python 설정
PYTHONUNBUFFERED=1
PYTHONPATH=/app
# 문서 처리 설정
MAX_FILE_SIZE=20971520
SUPPORTED_FILE_TYPES=txt,pdf,docx,md
