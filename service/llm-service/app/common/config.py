import os
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# =============================================================================
# ğŸš€ ì„œë¹„ìŠ¤ ì„¤ì •
# =============================================================================
SERVICE_NAME = os.getenv("SERVICE_NAME", "llm-service")
SERVICE_HOST = os.getenv("SERVICE_HOST", "0.0.0.0")
SERVICE_PORT = int(os.getenv("PORT", "8000"))  # Docker Compose(8009) ë° Railwayì—ì„œ ìë™ìœ¼ë¡œ PORT í™˜ê²½ë³€ìˆ˜ ì œê³µ

# =============================================================================
# ğŸ“ FAISS Volume ì„¤ì • (vectordb êµ¬ì¡°)
# =============================================================================
FAISS_VOLUME_PATH = os.getenv("FAISS_VOLUME_PATH", "./vectordb")
FAISS_INDEX_NAME = os.getenv("FAISS_INDEX_NAME", "sr_corpus")
FAISS_STORE_NAME = os.getenv("FAISS_STORE_NAME", "sr_corpus")

# FAISS íŒŒì¼ ê²½ë¡œ (ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œ)
FAISS_INDEX_PATH = Path(FAISS_VOLUME_PATH) / FAISS_INDEX_NAME / "index.faiss"
FAISS_STORE_PATH = Path(FAISS_VOLUME_PATH) / FAISS_STORE_NAME / "index.pkl"

# TCFD ê¸°ì¤€ì„œ FAISS íŒŒì¼ ê²½ë¡œ (ì¶”ê°€)
TCFD_INDEX_PATH = Path(FAISS_VOLUME_PATH) / "standards" / "index.faiss"
TCFD_STORE_PATH = Path(FAISS_VOLUME_PATH) / "standards" / "index.pkl"

# =============================================================================
# ğŸ”¤ ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ì´ë¯¸ ì„ë² ë”©ëœ FAISS ì‚¬ìš©)
# =============================================================================
# ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ì˜ ì°¨ì› (ì°¨ì› ì¼ì¹˜ ê²€ì¦ìš©)
EMBED_DIM = int(os.getenv("EMBED_DIM", "1536"))
# OpenAI API í‚¤ (í…ìŠ¤íŠ¸ ìƒì„±ìš©ë§Œ)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# =============================================================================
# ğŸ¤– ìƒì„± ëª¨ë¸ ì„¤ì •
# =============================================================================
# OpenAI ì„¤ì •
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_MAX_TOKENS = int(os.getenv("OPENAI_MAX_TOKENS", "2000"))
OPENAI_TEMPERATURE = float(os.getenv("OPENAI_TEMPERATURE", "0.3"))

# ì™¸ë¶€ GPU(vLLM/TGI) KoAlpaca ì„¤ì •
GENAI_URL = os.getenv("GENAI_URL", "")
GENAI_KEY = os.getenv("GENAI_KEY", "")

# Hugging Face ì„¤ì •
HF_API_URL = os.getenv("HF_API_URL", "https://api-inference.huggingface.co")
HF_API_TOKEN = os.getenv("HF_API_TOKEN", "")  # ë¹ˆ ë¬¸ìì—´ì´ë©´ fallback ëª¨ë“œë¡œ ë™ì‘
HF_MODEL = os.getenv("HF_MODEL", "EleutherAI/polyglot-ko-3.8b")
HF_TIMEOUT = int(os.getenv("HF_TIMEOUT", "30"))

# =============================================================================
# ğŸ”’ ë³´ì•ˆ ì„¤ì •
# =============================================================================
ADMIN_TOKEN = os.getenv("ADMIN_TOKEN", "supersecret")

# =============================================================================
# ğŸ“Š ëª¨ë‹ˆí„°ë§ ì„¤ì •
# =============================================================================
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
ENABLE_METRICS = os.getenv("ENABLE_METRICS", "true").lower() == "true"
ENABLE_LOGGING = os.getenv("ENABLE_LOGGING", "true").lower() == "true"

# =============================================================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° ì„¤ì •
# =============================================================================
MAX_FILE_SIZE = int(os.getenv("MAX_FILE_SIZE", "20971520"))  # 20MB
SUPPORTED_FILE_TYPES = os.getenv("SUPPORTED_FILE_TYPES", "txt,pdf,docx,md").split(",")

# ê¸°ë³¸ top_k ê°’
DEFAULT_TOP_K = 5
MAX_TOP_K = 20
