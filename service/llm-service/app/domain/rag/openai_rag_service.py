import faiss
import numpy as np
import pickle
import logging
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
from ...common.config import (
    get_faiss_index_path, get_faiss_store_path,
    FAISS_VOLUME_PATH, FAISS_INDEX_NAME,
    EMBED_DIM, OPENAI_API_KEY, OPENAI_MODEL,
    OPENAI_MAX_TOKENS, OPENAI_TEMPERATURE
)
from ...common.schemas import SearchHit
from .base_rag_service import BaseRAGService
from ..llm.openai_llm_service import OpenAILLMService

logger = logging.getLogger(__name__)

class OpenAIRAGService(BaseRAGService):
    """OpenAI ê¸°ë°˜ RAG ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        super().__init__("OpenAI RAG Service")
        self.index: Optional[faiss.Index] = None
        self.doc_store: Optional[List[Dict[str, Any]]] = None
        self.llm_service = OpenAILLMService()
        
        # OpenAI API í‚¤ ê²€ì¦
        if not OPENAI_API_KEY:
            logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    
    def load_index(self) -> bool:
        """FAISS ì¸ë±ìŠ¤ì™€ ë¬¸ì„œ ì €ì¥ì†Œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            logger.info(f"FAISS ì¸ë±ìŠ¤ ë¡œë”© ì‹œë„: {get_faiss_index_path()}")
            logger.info(f"FAISS_VOLUME_PATH: {FAISS_VOLUME_PATH}")
            logger.info(f"FAISS_INDEX_NAME: {FAISS_INDEX_NAME}")
            logger.info(f"FAISS_INDEX_PATH íƒ€ì…: {type(get_faiss_index_path())}")
            logger.info(f"FAISS_INDEX_PATH ë¬¸ìì—´: {str(get_faiss_index_path())}")
            
            # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            file_exists = get_faiss_index_path().exists()
            logger.info(f"íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {file_exists}")
            
            if not file_exists:
                logger.warning(f"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {get_faiss_index_path()}")
                # ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸
                parent_dir = get_faiss_index_path().parent
                if parent_dir.exists():
                    logger.info(f"ë¶€ëª¨ ë””ë ‰í† ë¦¬ ë‚´ìš©: {list(parent_dir.iterdir())}")
                return False
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            self.index = faiss.read_index(str(get_faiss_index_path()))
            logger.info(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {self.index.ntotal}ê°œ ë²¡í„°")
            
            # ë¬¸ì„œ ì €ì¥ì†Œ ë¡œë”© ì‹œë„
            try:
                store_path = get_faiss_store_path()
                logger.info(f"ğŸ“– PKL ë¬¸ì„œ ì €ì¥ì†Œ ë¡œë”© ì‹œë„: {store_path}")
                
                if store_path.exists():
                    with open(store_path, 'rb') as f:
                        self.doc_store = pickle.load(f)
                    logger.info(f"âœ… ë¬¸ì„œ ì €ì¥ì†Œ ë¡œë”© ì™„ë£Œ: {len(self.doc_store)}ê°œ ë¬¸ì„œ")
                else:
                    logger.warning(f"âš ï¸ ë¬¸ì„œ ì €ì¥ì†Œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {store_path}")
                    self.doc_store = None
            except Exception as pkl_error:
                logger.error(f"âŒ PKL íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {str(pkl_error)}")
                
                # Pydantic í˜¸í™˜ì„± ë¬¸ì œ ì‹œë„ í•´ê²°
                if '__fields_set__' in str(pkl_error):
                    logger.info("ğŸ”„ Pydantic v1/v2 í˜¸í™˜ì„± ë¬¸ì œ ê°ì§€, ëŒ€ì²´ ë°©ë²• ì‹œë„")
                    try:
                        # Pydantic v1 ê°ì²´ë¥¼ v2ë¡œ ë³€í™˜í•˜ëŠ” ì‹œë„
                        with open(store_path, 'rb') as f:
                            raw_data = pickle.load(f)
                        
                        # v1 ê°ì²´ì˜ __fields_set__ ë¬¸ì œ í•´ê²°
                        if isinstance(raw_data, dict):
                            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜ ì‹œë„
                            converted_data = {}
                            for key, value in raw_data.items():
                                if hasattr(value, '__dict__'):
                                    # ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                                    converted_data[key] = value.__dict__
                                else:
                                    converted_data[key] = value
                            self.doc_store = converted_data
                            logger.info(f"âœ… Pydantic v1/v2 í˜¸í™˜ì„± ì²˜ë¦¬ë¡œ ë¬¸ì„œ ì €ì¥ì†Œ ë¡œë”© ì„±ê³µ: {len(self.doc_store)}ê°œ ë¬¸ì„œ")
                        else:
                            raise Exception("ë°ì´í„° í˜•íƒœ ë³€í™˜ ì‹¤íŒ¨")
                            
                    except Exception as compat_error:
                        logger.error(f"âŒ Pydantic í˜¸í™˜ì„± í•´ê²° ì‹œë„ ì‹¤íŒ¨: {str(compat_error)}")
                        self.doc_store = None
                        logger.warning("âš ï¸ ë¬¸ì„œ ì €ì¥ì†Œ ì—†ì´ FAISS ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©")
                else:
                    self.doc_store = None
                    logger.warning("âš ï¸ ë¬¸ì„œ ì €ì¥ì†Œ ì—†ì´ FAISS ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©")
            
            # ì°¨ì› ê²€ì¦
            if self.index.d != EMBED_DIM:
                logger.error(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: ì¸ë±ìŠ¤={self.index.d}, ì„¤ì •={EMBED_DIM}")
                return False
            
            self.is_loaded = True
            if self.doc_store:
                logger.info("OpenAI RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (FAISS ì¸ë±ìŠ¤ + ë¬¸ì„œ ì €ì¥ì†Œ)")
            else:
                logger.info("OpenAI RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (FAISS ì¸ë±ìŠ¤ë§Œ)")
            return True
            
        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
            self.is_loaded = False
            return False
    
    def search(self, query: str, top_k: int = 5) -> Tuple[List[SearchHit], str]:
        """FAISS ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        if not self.is_loaded:
            raise RuntimeError("RAG ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ë¬¸ì„œ ìŠ¤í† ì–´ ì—†ì´)
            # ì‹¤ì œë¡œëŠ” ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í•´ì•¼ í•˜ì§€ë§Œ,
            # í˜„ì¬ëŠ” ê¸°ë³¸ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´
            
            # ë”ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰)
            hits = []
            context_parts = []
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œë®¬ë ˆì´ì…˜
            query_lower = query.lower()
            keywords = query_lower.split()
            
            for i in range(min(top_k, 5)):  # ìµœëŒ€ 5ê°œ ê²°ê³¼
                # ë”ë¯¸ ë¬¸ì„œ ìƒì„±
                dummy_text = f"ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œ ê´€ë ¨ ë‚´ìš©: {query}ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œ {i+1}"
                
                hit = SearchHit(
                    rank=i + 1,
                    id=str(i),
                    score=1.0 / (i + 1),  # ìˆœìœ„ì— ë”°ë¥¸ ì ìˆ˜
                    text=dummy_text,
                    meta={"source": "sustainability_report", "type": "dummy"}
                )
                hits.append(hit)
                
                context_parts.append(f"[{i+1}] {dummy_text}")
            
            # ì»¨í…ìŠ¤íŠ¸ ì—°ê²°
            context = "\n\n---\n\n".join(context_parts)
            
            logger.info(f"OpenAI RAG ê²€ìƒ‰ ì™„ë£Œ (ë”ë¯¸ ëª¨ë“œ): {len(hits)}ê°œ ê²°ê³¼, top_k={top_k}")
            return hits, context
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise
    
    def generate_draft(self, question: str, sections: List[str], top_k: int = 8) -> str:
        """ì„¹ì…˜ë³„ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.is_loaded:
            raise RuntimeError("RAG ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            hits, context = self.search(question, top_k)
            
            # ê° ì„¹ì…˜ë³„ ì´ˆì•ˆ ìƒì„±
            draft_parts = []
            for section in sections:
                try:
                    draft_content = self.llm_service.generate_draft_section(
                        question=question,
                        context=context,
                        section=section
                    )
                    draft_parts.append(f"## {section}\n\n{draft_content}")
                except Exception as e:
                    logger.error(f"ì„¹ì…˜ {section} ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
                    draft_parts.append(f"## {section}\n\nì´ˆì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            return "\n\n".join(draft_parts)
            
        except Exception as e:
            logger.error(f"ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def polish_text(self, text: str, tone: str = "ê³µì‹ì ", style_guide: str = "") -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ìœ¤ë¬¸í•©ë‹ˆë‹¤."""
        try:
            return self.llm_service.polish_text(text, tone, style_guide)
        except Exception as e:
            logger.error(f"ìœ¤ë¬¸ ì‹¤íŒ¨: {e}")
            raise
