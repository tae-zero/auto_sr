import os
import json
import logging
from typing import List, Dict, Any, Optional
import numpy as np

logger = logging.getLogger(__name__)

class RAGService:
    """RAG ì„œë¹„ìŠ¤ - FAISS ì¸ë±ìŠ¤ë¥¼ í†µí•œ ì •ë³´ ê²€ìƒ‰"""
    
    def __init__(self):
        self.index_path = os.getenv('FAISS_VOLUME_PATH', '/data')  # Railway ë³¼ë¥¨ ê²½ë¡œ
        self.index_name = os.getenv('FAISS_INDEX_NAME', 'sr_corpus')
        self.store_name = os.getenv('FAISS_STORE_NAME', 'sr_corpus')
        
        logger.info(f"ðŸ”§ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        logger.info(f"  - index_path: {self.index_path}")
        logger.info(f"  - index_name: {self.index_name}")
        logger.info(f"  - store_name: {self.store_name}")
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë”© ìƒíƒœ
        self.is_index_loaded = False
        self.faiss_index = None
        self.doc_store = None
        
        # ì¸ë±ìŠ¤ ë¡œë”© ì‹œë„
        self._load_index()
    
    def _load_index(self):
        """FAISS ì¸ë±ìŠ¤ì™€ ë¬¸ì„œ ì €ìž¥ì†Œ ë¡œë”©"""
        try:
            import faiss
            import pickle
            
            # FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
            index_file = os.path.join(self.index_path, self.index_name, "index.faiss")
            store_file = os.path.join(self.index_path, self.store_name, "index.pkl")
            
            logger.info(f"ðŸ” RAG ì„œë¹„ìŠ¤ ì¸ë±ìŠ¤ ë¡œë”© ì‹œìž‘")
            logger.info(f"  - index_path: {self.index_path}")
            logger.info(f"  - index_name: {self.index_name}")
            logger.info(f"  - store_name: {self.store_name}")
            logger.info(f"  - index_file: {index_file}")
            logger.info(f"  - store_file: {store_file}")
            
            # íŒŒì¼ ì¡´ìž¬ í™•ì¸
            if not os.path.exists(index_file):
                logger.warning(f"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŒ: {index_file}")
                self.is_index_loaded = False
                return
                
            if not os.path.exists(store_file):
                logger.warning(f"ë¬¸ì„œ ì €ìž¥ì†Œ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŒ: {store_file}")
                self.is_index_loaded = False
                return
            
            # ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸
            index_dir = os.path.dirname(index_file)
            store_dir = os.path.dirname(store_file)
            
            if os.path.exists(index_dir):
                logger.info(f"ðŸ“ ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ ë‚´ìš©: {os.listdir(index_dir)}")
            if os.path.exists(store_dir):
                logger.info(f"ðŸ“ ì €ìž¥ì†Œ ë””ë ‰í† ë¦¬ ë‚´ìš©: {os.listdir(store_dir)}")
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë”©
            self.faiss_index = faiss.read_index(index_file)
            logger.info(f"FAISS ì¸ë±ìŠ¤ ë¡œë”© ì™„ë£Œ: {self.faiss_index.ntotal}ê°œ ë¬¸ì„œ")
            
            # ë¬¸ì„œ ì €ìž¥ì†Œ ë¡œë”©
            try:
                logger.info(f"ðŸ“– PKL íŒŒì¼ ë¡œë”© ì‹œë„: {store_file}")
                with open(store_file, 'rb') as f:
                    self.doc_store = pickle.load(f)
                logger.info(f"âœ… ë¬¸ì„œ ì €ìž¥ì†Œ ë¡œë”© ì™„ë£Œ: {len(self.doc_store)}ê°œ ë¬¸ì„œ")
            except Exception as pkl_error:
                logger.error(f"âŒ PKL íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {str(pkl_error)}")
                logger.error(f"  - íŒŒì¼ ê²½ë¡œ: {store_file}")
                logger.error(f"  - íŒŒì¼ í¬ê¸°: {os.path.getsize(store_file) if os.path.exists(store_file) else 'íŒŒì¼ ì—†ìŒ'}")
                # PKL ë¡œë”© ì‹¤íŒ¨ ì‹œì—ë„ FAISSëŠ” ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
                self.doc_store = None
                logger.warning("âš ï¸ ë¬¸ì„œ ì €ìž¥ì†Œ ì—†ì´ FAISS ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©")
            
            self.is_index_loaded = True
            logger.info("FAISS ì¸ë±ìŠ¤ ë¡œë”© ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"FAISS ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            self.is_index_loaded = False
    
    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            if not self.is_index_loaded:
                logger.warning("FAISS ì¸ë±ìŠ¤ê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return self._get_dummy_results(query, top_k)
            
            # ë¬¸ì„œ ì €ìž¥ì†Œ í™•ì¸
            if self.doc_store is None:
                logger.warning("âš ï¸ ë¬¸ì„œ ì €ìž¥ì†Œ(PKL)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return self._get_dummy_results(query, top_k)
            
            # ì‹¤ì œ FAISS ê²€ìƒ‰ ë¡œì§ êµ¬í˜„
            logger.info(f"ì¿¼ë¦¬ ê²€ìƒ‰: '{query}' (top_k: {top_k})")
            logger.info(f"ðŸ“š ë¬¸ì„œ ì €ìž¥ì†Œ ìƒíƒœ: {len(self.doc_store)}ê°œ ë¬¸ì„œ")
            
            # ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ TF-IDF ìŠ¤íƒ€ì¼)
            query_tokens = query.lower().split()
            
            # ë¬¸ì„œ ì €ìž¥ì†Œì—ì„œ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ê²€ìƒ‰
            relevant_docs = []
            for doc_id, doc_content in self.doc_store.items():
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                score = 0
                doc_tokens = doc_content.lower().split()
                
                for token in query_tokens:
                    if token in doc_tokens:
                        score += 1
                
                if score > 0:
                    relevant_docs.append({
                        'content': doc_content,
                        'score': score / len(query_tokens),  # ì •ê·œí™”ëœ ì ìˆ˜
                        'source': f'Document_{doc_id}',
                        'metadata': {
                            'category': 'TCFD',
                            'type': 'corpus'
                        }
                    })
            
            # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  top_kë§Œ ë°˜í™˜
            relevant_docs.sort(key=lambda x: x['score'], reverse=True)
            results = relevant_docs[:top_k]
            
            if not results:
                logger.info("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë”ë¯¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return self._get_dummy_results(query, top_k)
            
            logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return results
            
        except Exception as e:
            logger.error(f"RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self._get_dummy_results(query, top_k)
    
    def _get_dummy_results(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """ë”ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜ (í…ŒìŠ¤íŠ¸ìš©)"""
        dummy_results = []
        
        # TCFD ê´€ë ¨ ë”ë¯¸ ë°ì´í„°
        tcfd_content = [
            "TCFD(Task Force on Climate-related Financial Disclosures)ëŠ” ê¸°í›„ ê´€ë ¨ ìž¬ë¬´ì •ë³´ ê³µì‹œë¥¼ ìœ„í•œ êµ­ì œ í‘œì¤€ í”„ë ˆìž„ì›Œí¬ìž…ë‹ˆë‹¤.",
            "ê±°ë²„ë„ŒìŠ¤ ì˜ì—­ì—ì„œëŠ” ê¸°í›„ ê´€ë ¨ ìœ„í—˜ê³¼ ê¸°íšŒì— ëŒ€í•œ ì´ì‚¬íšŒ ê°ë… ë° ê²½ì˜ì§„ ì—­í• ì„ ëª…í™•ížˆ í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ì „ëžµ ì˜ì—­ì—ì„œëŠ” ê¸°í›„ ê´€ë ¨ ìœ„í—˜ê³¼ ê¸°íšŒê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê³  ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ìœ„í—˜ê´€ë¦¬ ì˜ì—­ì—ì„œëŠ” ê¸°í›„ ê´€ë ¨ ìœ„í—˜ì„ ì‹ë³„, í‰ê°€, ê´€ë¦¬í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ì „ì‚¬ì  ìœ„í—˜ê´€ë¦¬ ì²´ê³„ì— í†µí•©í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ì§€í‘œ ë° ëª©í‘œ ì˜ì—­ì—ì„œëŠ” ê¸°í›„ ê´€ë ¨ ìœ„í—˜ê³¼ ê¸°íšŒë¥¼ í‰ê°€í•˜ëŠ” ì§€í‘œë¥¼ ì„¤ì •í•˜ê³  êµ¬ì²´ì ì¸ ëª©í‘œë¥¼ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤."
        ]
        
        for i in range(min(top_k, len(tcfd_content))):
            dummy_results.append({
                'content': tcfd_content[i],
                'score': 0.9 - (i * 0.1),
                'source': f'TCFD_Standard_{i+1}',
                'metadata': {
                    'category': 'TCFD',
                    'type': 'standard'
                }
            })
        
        return dummy_results
    
    def get_service_status(self) -> Dict[str, Any]:
        """RAG ì„œë¹„ìŠ¤ ìƒíƒœ ë°˜í™˜"""
        return {
            'is_loaded': self.is_index_loaded,
            'index_path': self.index_path,
            'index_name': self.index_name,
            'store_name': self.store_name
        }

    def search_openai(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """OpenAIìš© RAG ê²€ìƒ‰ (TCFD ë³´ê³ ì„œ ì„œë¹„ìŠ¤ í˜¸í™˜ì„±)"""
        return self.search(query, top_k)
    
    def search_huggingface(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Hugging Faceìš© RAG ê²€ìƒ‰ (TCFD ë³´ê³ ì„œ ì„œë¹„ìŠ¤ í˜¸í™˜ì„±)"""
        return self.search(query, top_k)
