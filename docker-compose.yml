name: esg_mate

services:
  # Frontend (Next.js)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: frontend
    ports:
      - "${FRONTEND_PORT:-3001}:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
      - /app/.pnpm-store
    env_file: .env
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:8080/api}
      - NEXT_PUBLIC_GATEWAY_URL=${NEXT_PUBLIC_GATEWAY_URL:-http://localhost:8080}
      - WATCHPACK_POLLING=${WATCHPACK_POLLING:-true}
      - CHOKIDAR_USEPOLLING=${CHOKIDAR_USEPOLLING:-true}
    restart: always
    depends_on:
      gateway:
        condition: service_healthy
    networks:
      - app-network

  # Gateway (FastAPI)
  gateway:
    build: ./gateway
    container_name: gateway
    ports:
      - "${GATEWAY_PORT:-8080}:8080"
    volumes:
      - ./gateway:/app
    env_file: .env
    environment:
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - PORT=${GATEWAY_PORT:-8080}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - GATEWAY_HOST=${GATEWAY_HOST:-0.0.0.0}
      - GATEWAY_PORT=${GATEWAY_PORT:-8080}
      - GATEWAY_RELOAD=${GATEWAY_RELOAD:-false}
      - SERVICE_DISCOVERY_TYPE=${SERVICE_DISCOVERY_TYPE:-static}
      - LOAD_BALANCER_TYPE=${LOAD_BALANCER_TYPE:-round_robin}
      - REQUEST_TIMEOUT=${REQUEST_TIMEOUT:-30}
      - HEALTH_CHECK_INTERVAL=${HEALTH_CHECK_INTERVAL:-30}
      - CORS_ORIGINS=${CORS_ORIGINS:-["*"]}
      - CORS_ALLOW_CREDENTIALS=${CORS_ALLOW_CREDENTIALS:-true}
      - CORS_ALLOW_METHODS=${CORS_ALLOW_METHODS:-["*"]}
      - CORS_ALLOW_HEADERS=${CORS_ALLOW_HEADERS:-["*"]}
      - INIT_DATABASE=${INIT_DATABASE:-true}
      # JWT 설정
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      # Docker 로컬 환경 설정
      - RAILWAY_ENVIRONMENT=${RAILWAY_ENVIRONMENT:-false}
      - USE_RAILWAY_TCFD=${USE_RAILWAY_TCFD:-false}
      - USE_LOCAL_AUTH=${USE_LOCAL_AUTH:-true}
      - USE_LOCAL_CHATBOT=${USE_LOCAL_CHATBOT:-true}
      # Docker Service URLs 설정 (ServiceDiscovery 사용)
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL:-http://auth-service:8008}
      - TCFD_SERVICE_URL=${TCFD_SERVICE_URL:-http://tcfd-service:8005}
      - TCFD_REPORT_SERVICE_URL=${TCFD_REPORT_SERVICE_URL:-http://tcfdreport-service:8004}
      # 데이터베이스 연결
      - DATABASE_URL=${DATABASE_URL}
      # AI 및 LangChain 설정
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-2000}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.3}
      - VECTOR_DB_TYPE=${VECTOR_DB_TYPE:-chroma}
      - CHROMA_PERSIST_DIRECTORY=${CHROMA_PERSIST_DIRECTORY:-./chroma_db}
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-20971520}
      - SUPPORTED_FILE_TYPES=${SUPPORTED_FILE_TYPES:-txt,pdf,docx,md}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      auth-service:
        condition: service_healthy
      tcfd-service:
        condition: service_healthy
      tcfdreport-service:
        condition: service_healthy
      llm-service:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # Chatbot Service (FastAPI)
  chatbot-service:
    build:
      context: ./service/chatbot-service
      dockerfile: Dockerfile
    container_name: chatbot-service
    ports:
      - "${CHATBOT_SERVICE_PORT:-8001}:8001"
    volumes:
      - ./service/chatbot-service:/app
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - SERVICE_PORT=${CHATBOT_SERVICE_PORT:-8001}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
    restart: always
    depends_on:
      - redis
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # TCFD Service (FastAPI + 재무정보 처리)
  tcfd-service:
    build:
      context: ./service/tcfd-service
      dockerfile: Dockerfile
    container_name: tcfd-service
    ports:
      - "${TCFD_SERVICE_PORT:-8005}:8005"
    volumes:
      - ./service/tcfd-service:/app
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - SERVICE_PORT=${TCFD_SERVICE_PORT:-8005}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      # 데이터베이스 연결
      - DATABASE_URL=${DATABASE_URL}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # TCFD Report Service (FastAPI + LangChain + AI 보고서 생성)
  tcfdreport-service:
    build:
      context: ./service/tcfdreport-service
      dockerfile: Dockerfile
    container_name: tcfdreport-service
    ports:
      - "${TCFD_REPORT_SERVICE_PORT:-8004}:8004"
    volumes:
      - ./service/tcfdreport-service:/app
      - tcfd_chroma_data:/app/chroma_db
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - SERVICE_PORT=${TCFD_REPORT_SERVICE_PORT:-8004}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      # JWT 설정
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      # 데이터베이스 설정
      - DATABASE_URL=${DATABASE_URL}
      # AI 및 LangChain 설정
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-2000}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.3}
      - VECTOR_DB_TYPE=${VECTOR_DB_TYPE:-chroma}
      - CHROMA_PERSIST_DIRECTORY=${CHROMA_PERSIST_DIRECTORY:-./chroma_db}
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-20971520}
      - SUPPORTED_FILE_TYPES=${SUPPORTED_FILE_TYPES:-txt,pdf,docx,md}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # GRI Service (FastAPI)
  gri-service:
    build:
      context: ./service/gri-service
      dockerfile: Dockerfile
    container_name: gri-service
    ports:
      - "${GRI_SERVICE_PORT:-8006}:8006"
    volumes:
      - ./service/gri-service:/app
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - SERVICE_PORT=${GRI_SERVICE_PORT:-8006}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - INIT_DATABASE=${INIT_DATABASE:-true}
      # 데이터베이스 연결
      - DATABASE_URL=${DATABASE_URL}
      - SECRET_KEY=${SECRET_KEY:-esg-mate-secret-key}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8006/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # Materiality Service (FastAPI)
  materiality-service:
    build:
      context: ./service/materiality-service
      dockerfile: Dockerfile
    container_name: materiality-service
    ports:
      - "${MATERIALITY_SERVICE_PORT:-8007}:8007"
    volumes:
      - ./service/materiality-service:/app
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - SERVICE_PORT=${MATERIALITY_SERVICE_PORT:-8007}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - INIT_DATABASE=${INIT_DATABASE:-true}
      # 데이터베이스 연결
      - DATABASE_URL=${DATABASE_URL}
      - SECRET_KEY=${SECRET_KEY:-esg-mate-secret-key}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8007/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # LLM Service (FastAPI + RAG + AI)
  llm-service:
    build:
      context: ./service/llm-service
      dockerfile: Dockerfile
    container_name: llm-service
    ports:
      - "${LLM_SERVICE_PORT:-8002}:8002"
    volumes:
      - ./service/llm-service/vectordb:/app/vectordb
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - PORT=8002
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      # FAISS 설정
      - FAISS_VOLUME_PATH=/app/vectordb
      - FAISS_INDEX_NAME=sr_corpus
      - FAISS_STORE_NAME=sr_corpus
      - EMBED_DIM=${EMBED_DIM:-768}
      # OpenAI 설정
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-2000}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.3}
      # Hugging Face 설정
      - HF_API_URL=${HF_API_URL:-https://api-inference.huggingface.co}
      - HF_API_TOKEN=${HF_API_TOKEN}
      - HF_MODEL=${HF_MODEL:-EleutherAI/polyglot-ko-3.8b}
      - HF_TIMEOUT=${HF_TIMEOUT:-30}
      # 외부 GPU 설정
      - GENAI_URL=${GENAI_URL}
      - GENAI_KEY=${GENAI_KEY}
      # 보안 설정
      - ADMIN_TOKEN=${ADMIN_TOKEN:-supersecret}
      # 모니터링 설정
      - ENABLE_METRICS=${ENABLE_METRICS:-true}
      - ENABLE_LOGGING=${ENABLE_LOGGING:-true}
      # 유틸리티 설정
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-20971520}
      - SUPPORTED_FILE_TYPES=${SUPPORTED_FILE_TYPES:-txt,pdf,docx,md}
      - DEFAULT_TOP_K=${DEFAULT_TOP_K:-5}
      - MAX_TOP_K=${MAX_TOP_K:-20}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s

  # Auth Service (FastAPI)
  auth-service:
    build:
      context: ./service/auth-service
      dockerfile: Dockerfile
    container_name: auth-service
    ports:
      - "${AUTH_SERVICE_PORT:-8008}:8008"
    volumes:
      - ./service/auth-service:/app
    env_file: .env
    environment:
      - SERVICE_HOST=${SERVICE_HOST:-0.0.0.0}
      - SERVICE_PORT=${AUTH_SERVICE_PORT:-8008}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - INIT_DATABASE=${INIT_DATABASE:-true}
      # JWT 설정
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      # Database 설정
      - DATABASE_URL=${DATABASE_URL}
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Redis (캐싱 및 세션 저장)
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - app-network
    restart: always
    command: redis-server
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

volumes:
  tcfd_chroma_data:
    driver: local
  llm_vectordb_data:
    driver: local

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16